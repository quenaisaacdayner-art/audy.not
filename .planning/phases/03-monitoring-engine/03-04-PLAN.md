---
phase: 03-monitoring-engine
plan: 04
type: execute
wave: 2
depends_on: ["03-01", "03-02", "03-03"]
files_modified:
  - vercel.json
  - src/app/api/cron/monitor/route.ts
  - src/actions/mentions.ts
autonomous: true
user_setup:
  - service: vercel
    why: "Cron job authentication"
    env_vars:
      - name: CRON_SECRET
        source: "Generate random string (e.g., openssl rand -hex 32) and add to Vercel Environment Variables"
    dashboard_config:
      - task: "Add CRON_SECRET environment variable"
        location: "Vercel Dashboard -> Project -> Settings -> Environment Variables"

must_haves:
  truths:
    - "Cron job runs every 15 minutes"
    - "Only authorized requests (CRON_SECRET) can trigger monitoring"
    - "System fetches posts from all user subreddits"
    - "Posts are filtered by keywords"
    - "Qualifying posts are classified and get draft replies"
    - "Same post is not processed twice for same product (deduplication)"
  artifacts:
    - path: "vercel.json"
      provides: "Cron schedule configuration"
      contains: "*/15 * * * *"
    - path: "src/app/api/cron/monitor/route.ts"
      provides: "Cron endpoint handler"
      exports: ["GET", "maxDuration"]
      min_lines: 80
    - path: "src/actions/mentions.ts"
      provides: "Mention database operations"
      exports: ["createMention", "getMentions", "getMention", "updateMentionStatus"]
  key_links:
    - from: "src/app/api/cron/monitor/route.ts"
      to: "src/lib/reddit/client.ts"
      via: "fetchSubredditPosts import"
      pattern: "fetchSubredditPosts"
    - from: "src/app/api/cron/monitor/route.ts"
      to: "src/lib/openai/client.ts"
      via: "classifyPostIntent, generateDraftReply imports"
      pattern: "classifyPostIntent|generateDraftReply"
    - from: "src/app/api/cron/monitor/route.ts"
      to: "src/actions/mentions.ts"
      via: "createMention import"
      pattern: "createMention"
---

<objective>
Create the cron-based monitoring engine that orchestrates Reddit polling, AI processing, and mention creation.

Purpose: Automate the discovery of Reddit opportunities by polling configured subreddits every 15 minutes, classifying posts, and generating draft replies.
Output: Working cron endpoint that processes all user products and creates mentions for qualifying posts.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-monitoring-engine/03-RESEARCH.md
@.planning/phases/03-monitoring-engine/03-CONTEXT.md

@src/lib/supabase/server.ts
@src/actions/products.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create mentions server actions</name>
  <files>src/actions/mentions.ts</files>
  <action>
Create new file src/actions/mentions.ts following patterns from products.ts:

**Imports:**
```typescript
'use server'

import { createClient } from '@/lib/supabase/server'
import { revalidatePath } from 'next/cache'
import type { Mention, MentionStatus } from '@/types/database'
import { mentionStatusSchema } from '@/lib/validations/mention'
```

**Note:** Add MentionStatus type to database.ts if not already there:
```typescript
export type MentionStatus = 'pending' | 'approved' | 'discarded' | 'regenerated'
```

**createMention function** (for cron job use):
```typescript
export interface CreateMentionInput {
  product_id: string
  user_id: string
  reddit_post_id: string
  reddit_permalink: string
  reddit_title: string
  reddit_content: string | null
  reddit_author: string
  reddit_subreddit: string
  reddit_created_at: string
  intent: 'pain_point' | 'recommendation_request'
  confidence: number
  draft_reply: string | null
}

export async function createMention(input: CreateMentionInput): Promise<{ success: boolean; id?: string; error?: string }>
```
- Insert into mentions table with status: 'pending'
- Return { success: true, id } or { success: false, error }
- Note: This function is called by cron, not user-facing (no auth check needed in action itself, cron validates CRON_SECRET)

**checkMentionExists function** (for deduplication):
```typescript
export async function checkMentionExists(
  productId: string,
  redditPostId: string
): Promise<boolean>
```
- Query mentions table for existing (product_id, reddit_post_id) combo
- Return true if exists, false otherwise
- Uses service role context (called from cron)

**getMentions function** (for UI):
```typescript
export async function getMentions(filters?: {
  status?: MentionStatus
  productId?: string
}): Promise<Mention[]>
```
- Get authenticated user
- Query mentions with user_id = user.id
- Apply optional status and productId filters
- Order by created_at descending
- Join with products to include product.name

**getMention function** (for detail page):
```typescript
export async function getMention(id: string): Promise<Mention | null>
```
- Get authenticated user
- Query single mention by id where user_id = user.id
- Return null if not found or unauthorized

**updateMentionStatus function** (for Telegram actions in Phase 4):
```typescript
export async function updateMentionStatus(
  id: string,
  status: MentionStatus
): Promise<{ success: boolean; error?: string }>
```
- Validate status with mentionStatusSchema
- Get authenticated user
- Update mention status where id and user_id match
- Update updated_at timestamp
- Revalidate /mentions and /mentions/[id] paths
  </action>
  <verify>`npx tsc --noEmit` passes, functions are exported</verify>
  <done>Mention CRUD operations available for cron job and UI</done>
</task>

<task type="auto">
  <name>Task 2: Create Vercel cron configuration</name>
  <files>vercel.json</files>
  <action>
Create vercel.json in project root with cron schedule:

```json
{
  "$schema": "https://openapi.vercel.sh/vercel.json",
  "crons": [
    {
      "path": "/api/cron/monitor",
      "schedule": "*/15 * * * *"
    }
  ]
}
```

This schedules the monitoring cron job to run every 15 minutes.

Note: On Vercel Hobby plan, crons may have hourly precision. The schedule expresses intent; actual execution depends on plan tier.
  </action>
  <verify>File exists with valid JSON</verify>
  <done>Vercel cron configured for 15-minute intervals</done>
</task>

<task type="auto">
  <name>Task 3: Create cron monitoring endpoint</name>
  <files>src/app/api/cron/monitor/route.ts</files>
  <action>
Create new file src/app/api/cron/monitor/route.ts:

**Configuration:**
```typescript
export const maxDuration = 60  // Allow up to 60 seconds
```

**GET handler:**
```typescript
import type { NextRequest } from 'next/server'
import { createClient } from '@/lib/supabase/server'
import { fetchSubredditPosts, filterPostsByKeywords } from '@/lib/reddit/client'
import { classifyPostIntent, generateDraftReply } from '@/lib/openai/client'
import { createMention, checkMentionExists } from '@/actions/mentions'

export async function GET(request: NextRequest) {
  // 1. Verify CRON_SECRET
  const authHeader = request.headers.get('authorization')
  if (authHeader !== `Bearer ${process.env.CRON_SECRET}`) {
    return new Response('Unauthorized', { status: 401 })
  }

  const supabase = await createClient()
  const stats = { products: 0, posts_found: 0, mentions_created: 0 }

  try {
    // 2. Get all products with their user's persona
    // Query products joined with personas (same user_id)
    const { data: products, error: productsError } = await supabase
      .from('products')
      .select(`
        id, user_id, name, description, url, keywords, subreddits,
        personas!products_user_id_fkey(expertise, tone, phrases_to_avoid)
      `)

    if (productsError) {
      console.error('Failed to fetch products:', productsError)
      return Response.json({ success: false, error: 'Failed to fetch products' }, { status: 500 })
    }

    if (!products?.length) {
      return Response.json({ success: true, message: 'No products to monitor', stats })
    }

    stats.products = products.length

    // 3. Process each product
    for (const product of products) {
      // Skip if no subreddits configured
      if (!product.subreddits?.length) continue

      // Fetch posts from all subreddits
      for (const subreddit of product.subreddits) {
        const fetchResult = await fetchSubredditPosts(subreddit)
        if (!fetchResult.success) {
          console.warn(`Failed to fetch r/${subreddit}:`, fetchResult.error)
          continue
        }

        // Filter by keywords
        const relevant = product.keywords?.length
          ? filterPostsByKeywords(fetchResult.posts, product.keywords)
          : fetchResult.posts

        stats.posts_found += relevant.length

        // Process each relevant post
        for (const post of relevant) {
          // Deduplication check
          const exists = await checkMentionExists(product.id, post.id)
          if (exists) continue

          // Classify intent
          const classification = await classifyPostIntent(
            post.title,
            post.selftext,
            { name: product.name, description: product.description || '', keywords: product.keywords || [] }
          )

          if (!classification.success) {
            console.warn(`Classification failed for post ${post.id}:`, classification.error)
            continue
          }

          // Skip not_relevant posts
          if (classification.data?.intent === 'not_relevant') continue

          // Generate draft reply
          // Get persona from joined data (personas is an array due to join, take first)
          const persona = Array.isArray(product.personas) ? product.personas[0] : product.personas

          const reply = await generateDraftReply(
            { title: post.title, content: post.selftext },
            { name: product.name, description: product.description || '', url: product.url || undefined },
            persona || {}
          )

          // Create mention (even if reply generation failed - draft_reply can be null)
          const mentionResult = await createMention({
            product_id: product.id,
            user_id: product.user_id,
            reddit_post_id: post.id,
            reddit_permalink: `https://reddit.com${post.permalink}`,
            reddit_title: post.title,
            reddit_content: post.selftext || null,
            reddit_author: post.author,
            reddit_subreddit: post.subreddit,
            reddit_created_at: new Date(post.created_utc * 1000).toISOString(),
            intent: classification.data!.intent as 'pain_point' | 'recommendation_request',
            confidence: classification.data!.confidence,
            draft_reply: reply.data?.reply || null,
          })

          if (mentionResult.success) {
            stats.mentions_created++
          }
        }
      }
    }

    // 4. Update monitoring state
    await supabase
      .from('monitoring_state')
      .upsert({
        id: 1,
        last_checked_at: new Date().toISOString(),
        last_run_stats: stats,
      })

    return Response.json({ success: true, stats })
  } catch (error) {
    console.error('Monitoring error:', error)
    return Response.json({ success: false, error: 'Monitoring failed' }, { status: 500 })
  }
}
```

**Note about Supabase join:** The query `personas!products_user_id_fkey` attempts to join via foreign key relationship. If this doesn't work due to no explicit FK between products and personas, change to a separate query:
```typescript
// Alternative: Fetch persona separately
const { data: persona } = await supabase
  .from('personas')
  .select('expertise, tone, phrases_to_avoid')
  .eq('user_id', product.user_id)
  .single()
```

Choose the approach that works with the schema. The key is getting the persona for the user who owns the product.
  </action>
  <verify>
1. `npx tsc --noEmit` passes
2. `npm run build` passes
3. Route exists at /api/cron/monitor</verify>
  <done>Monitoring cron endpoint processes all products and creates mentions</done>
</task>

</tasks>

<verification>
1. [ ] vercel.json exists with cron schedule
2. [ ] src/actions/mentions.ts exports createMention, getMentions, getMention, updateMentionStatus, checkMentionExists
3. [ ] src/app/api/cron/monitor/route.ts exists with GET handler
4. [ ] CRON_SECRET validation is in place
5. [ ] maxDuration = 60 is set
6. [ ] `npx tsc --noEmit` passes
7. [ ] `npm run build` passes
</verification>

<success_criteria>
- Cron endpoint is protected by CRON_SECRET
- Products are fetched with their owner's persona
- Reddit posts are fetched from configured subreddits
- Posts are filtered by keywords
- Posts are classified by AI intent
- Draft replies are generated for qualifying posts
- Deduplication prevents duplicate mentions
- Monitoring state is updated with last_checked_at
</success_criteria>

<output>
After completion, create `.planning/phases/03-monitoring-engine/03-04-SUMMARY.md`
</output>
